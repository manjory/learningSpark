What I couldn't fully accomplish:
Docker container lifecycle confusion:

I had multiple Spark-related containers exiting soon after start.

Attempts to restart spark-master didn’t keep it running or show up in docker ps.

I ran into issues running commands inside containers because containers were stopped or exited.

I tried docker exec commands on containers that were not running.

There was confusion about how to properly keep the Spark master container alive and interactive.

Port and network troubleshooting:

I tried remapping Spark UI port from 8081 to 8085.

Curl commands to localhost ports 8080, 8081, 8085 failed or reset connections.

I questioned if port remapping in Docker Compose was correct but didn’t fully verify connectivity or container logs afterward.

Debugging Spark job container logs:

The job ran and completed successfully inside the container but the container exited immediately afterward.

I wanted help interpreting long logs to identify issues but the job appeared to finish cleanly.

I saw a common Hadoop native library warning which we confirmed as non-critical.

What I achieved:
Successfully submitted a Spark job inside a container (spark-submit).

Confirmed that Spark jobs completed successfully with logs.

Identified that containers exited after job completion, which is expected behavior unless containers run services persistently.

Confirmed the common Hadoop native library warning is harmless.

Recommended next steps / problem focus:
If I want to keep Spark services running interactively:

I can start Spark master and workers with long-running commands (e.g., run the master in the foreground).

Consider using Docker Compose with services configured to run in the foreground.

If I want to submit batch jobs and analyze outputs:

Focus on managing container lifecycle (maybe run jobs inside containers and save results to volumes).

Confirm ports are correctly mapped and accessible from host.

Otherwise, ready to move to my next problem or project!
